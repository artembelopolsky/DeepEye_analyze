{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### This notebook was designed to analyze data for Preferential Viewing Experiments.\n",
    "\n",
    "### Instructions for Use:\n",
    "1. Open the script in your Python environment (e.g., VS Code, Jupyter Notebook).\n",
    "2. Make sure you installed all the required libraries (listed in the first cell) in your custom environment.\n",
    "3. Run the script. It will automatically process all the participant files in the data folder, apply the necessary functions, and save the results in the analysis folder.\n",
    "\n",
    "### What it does:\n",
    "1. Creates Directories for Saving Results\n",
    "The script creates a folder where the analysis results will be saved. If this folder already exists, the script will let you know. Otherwise, it will create it.\n",
    "2. Read and Process Data for Each Participant\n",
    "The script goes into a folder where the data files are stored, finds all subfolders (one per participant), and processes the files in each folder.\n",
    "3. For each participant:\n",
    "- The script reads a data file that ends with _record_extra.csv.\n",
    "- It filters the data to only include rows where the event named target_on occurred.\n",
    "- It adds additional information to the data, such as padding (which defines the space around areas of interest), the participant ID, and the dimensions of images used in the experiment.\n",
    "4. The script adds details about images shown during the experiment, such as their paths, coordinates, and bounding boxes (which define areas of interest on the screen).\n",
    "Each image shown to participants is identified as either \"left\" or \"right.\"\n",
    "5. Run Data Processing\n",
    "- plot2d(): Plots a scatter plot of the raw and fixation data for each condition. It has an option of plotting the stimuli images, they need to be in a folder specified in the dataframe.\n",
    "- getFixationLatency(): Determines when each fixation started relative to the target event\n",
    "- handle_carryover_fixations_and_merge(): Sometimes fixations start before or end after the event of interest. This fixes the fixation latency for these cases.\n",
    "- addAOI(): Assigns fixations to the predefined Areas of Interest\n",
    "- Combine Processed Data\n",
    "Once the data for each participant is processed, it is added to a list.\n",
    "After processing all participants, the script combines the data into a single file and saves it as allSubjects_PV_Young.csv in the analysis_new folder.\n",
    "6. Output and Save\n",
    "If any data was processed, the script combines it and saves it to a file. You will see a message indicating where the file was saved.\n",
    "If no data was processed, the script will print a message saying \"No data was processed.\"\n",
    "\n",
    "\n",
    "### The notebook returns in /analysis folder\n",
    "1. Plots of all trials\n",
    "2. Fixation dataframe for all subject\n",
    "3. Dataframe with novelty indices calculated\n",
    "\n",
    "### Adjusting the AOIs (bounding boxes) \n",
    "1. By default the AOIs are the image dimensions\n",
    "2. By using a $padding$ variable you can expand the AOIs on each side. This will also have an effect on plotting.\n",
    "\n",
    "### Important Columns\n",
    "1. $user\\_pred\\_px\\_x, user\\_pred\\_px\\_y$: raw gaze coordinates\n",
    "1. $FixXPos, FixYPos$: x,y position of fixations\n",
    "2. $FixStartEnd$: indicates wheter fixation was carried over the event boundaries or not\n",
    "3. $DistFromPrevFix$: distance from previous fixation in px (handy variable)\n",
    "4. $PrevFixSampTime$: timestamp of the previous fixation (handy variable)\n",
    "5. $PrevFixXPos, PrevFixYPos$: x,y position of preceeding fixation (handy variable)\n",
    "8. $FixLatency$: the latency of fixation relative to when the target was presented\n",
    "9. $FixationOrder$: the order of fixation during the event\n",
    "10. $FixDur$: the duration of fixation\n",
    "11. $AOI\\_bbox$: the number of the bounding box where fixation landed or None\n",
    "12. $AOI\\_stim$: which stimulus fixation landed\n",
    "13. $event$: the event during which the data is analyzed, usually *target_on* \n",
    "14. $targSampTime$: timestamp of when the target was presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "import ast   \n",
    "import re\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg  \n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# import DeepEye analysis functions\n",
    "from deepeye_analysis_package.getFixations import batch_extract_fixations\n",
    "from deepeye_analysis_package.preprocessing import getFixationLatency, handle_carryover_fixations_and_merge, addAOI\n",
    "from deepeye_analysis_package.plotting import plot2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the environment ('Home' or 'Office') and set the data path accordingly\n",
    "WHERE = 'Office'  # 'Office' or 'Home'\n",
    "\n",
    "if WHERE == 'Home':\n",
    "    path = r'C:/Users/aby600/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_PreferentialViewing/Pilot_PreferentialViewing/Young/Approved'\n",
    "else:\n",
    "    path = r'D:/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_PreferentialViewing/Pilot_PreferentialViewing/Young/Approved'\n",
    "\n",
    "# Define the AOI padding in pixels\n",
    "PADDING = 0  # padding of AOI on each side, used in plot2d() and addAOI()\n",
    "\n",
    "# Helper function to create a directory if it doesn't exist\n",
    "def create_directory_if_not_exists(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "        print(f\"Directory '{directory_path}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory_path}' already exists.\")\n",
    "\n",
    "# Define data analysis directories and create them if they don't exist yet\n",
    "path_to_data = os.path.join(path, 'data')\n",
    "path_to_analysis = os.path.join(path, 'analysis_new')\n",
    "create_directory_if_not_exists(path_to_analysis)\n",
    "\n",
    "# Initialize an empty list to hold the processed dataframes\n",
    "output_dfs = []\n",
    "\n",
    "# Get all folder names from the data directory\n",
    "folder_names = [name for name in os.listdir(path_to_data) if os.path.isdir(os.path.join(path_to_data, name))]\n",
    "\n",
    "# Process each participant's data\n",
    "for fn in folder_names:\n",
    "    path_to_file = os.path.join(path_to_data, fn, f'{fn}_record_extra.csv')\n",
    "\n",
    "    print(f'Processing participant {fn}...')\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path_to_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f'File does not exist: {path_to_file}')\n",
    "        continue\n",
    "\n",
    "    # Filter data to only include rows where the target was presented\n",
    "    df1 = df[df['event'] == 'target_on'].copy()\n",
    "\n",
    "    # Add padding, subject ID, and image dimensions to the dataframe\n",
    "    df1['padding'] = PADDING\n",
    "    df1['deepeye_id'] = fn\n",
    "    df1['imageDims'] = [(480, 480)] * len(df1)\n",
    "\n",
    "    # Add image paths and coordinates to the dataframe\n",
    "    df1['image_paths'] = df1.apply(lambda row: [row.imageLeft, row.imageRight], axis=1)\n",
    "    df1['image_coords'] = df1.apply(lambda row: [\n",
    "        (row.leftX, row.Y, row.imageDims[0], row.imageDims[1]),\n",
    "        (row.rightX, row.Y, row.imageDims[0], row.imageDims[1])\n",
    "    ], axis=1)\n",
    "\n",
    "    # Add bounding boxes and their names to the dataframe\n",
    "    df1['bboxes'] = df1.apply(lambda row: [\n",
    "        [row.leftX, row.Y, row.imageDims[0], row.imageDims[1]],\n",
    "        [row.rightX, row.Y, row.imageDims[0], row.imageDims[1]]\n",
    "    ], axis=1)\n",
    "    df1['bboxesNames'] = df1.apply(lambda row: ['left', 'right'], axis=1)\n",
    "\n",
    "    # Plot 2D fixations without saving the plot\n",
    "    # plot2d(df1, fn, path_to_analysis, condition='locStudiedImage', save=False)\n",
    "\n",
    "    # Process the data by applying preprocessing steps\n",
    "    df1 = getFixationLatency(df1)\n",
    "    df1 = handle_carryover_fixations_and_merge(df1, max_event_duration=4000)\n",
    "    df1 = addAOI(df1)\n",
    "\n",
    "    # Accumulate the processed dataframe for this participant\n",
    "    output_dfs.append(df1)\n",
    "\n",
    "# Concatenate all participants' data into one DataFrame\n",
    "if output_dfs:\n",
    "    output_df = pd.concat(output_dfs, ignore_index=True)\n",
    "    output_file = os.path.join(path_to_analysis, 'allSubjects_PV_Young.csv')\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    print(f'Combined data saved to {output_file}')\n",
    "else:\n",
    "    print('No data was processed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate novelty index and make a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testPhase_df = pd.read_csv(os.path.join(path_to_analysis, 'allSubjects_PV_Young.csv'))\n",
    "\n",
    "testPhase_df = output_df\n",
    "\n",
    "# Select only test phase\n",
    "testPhase_df = testPhase_df[testPhase_df.phase=='test']\n",
    "\n",
    "# Label the fixations on left or right side\n",
    "testPhase_df['FixatedNovel'] = np.where(testPhase_df.AOI_stim == testPhase_df.locStudiedImage, 'old', \n",
    "                                        np.where(testPhase_df.AOI_stim == 'None', 'None', 'novel'))\n",
    "\n",
    "novelty_data = []\n",
    "\n",
    "# Iterate through participants and trials\n",
    "for (deepeye_id, trialNr), group in testPhase_df.groupby(['deepeye_id','trialNr']):\n",
    "    \n",
    "    # Safely compute the proportion of novel fixations (fixCountProp)\n",
    "    fix_count_total = group.FixatedNovel.count()\n",
    "    fix_count_novel = group.FixatedNovel[group.FixatedNovel == 'novel'].count()\n",
    "    novelty_fix_count_prop = fix_count_novel / fix_count_total if fix_count_total != 0 else 0\n",
    "    \n",
    "    # Safely compute the proportion of fixation durations (fixDurProp)\n",
    "    fix_dur_total = group.FixDur.sum()\n",
    "    fix_dur_novel = group.FixDur[group.FixatedNovel == 'novel'].sum()\n",
    "    novelty_fix_dur_prop = fix_dur_novel / fix_dur_total if fix_dur_total != 0 else 0\n",
    "    \n",
    "    # Append the results to a list\n",
    "    novelty_data.append([deepeye_id, trialNr, novelty_fix_count_prop, novelty_fix_dur_prop])\n",
    "\n",
    "# Convert list to DataFrame\n",
    "novelty_df = pd.DataFrame(novelty_data, columns=['deepeye_id', 'trialNr', 'noveltyIdx_fixCountProp', 'noveltyIdx_fixDurProp'])\n",
    "\n",
    "# Merge additional data into novelty_df\n",
    "additional_columns = ['deepeye_id', 'trialNr', 'pp_id', 'imageLeft', 'imageRight', 'locStudiedImage']  # List the columns you want to keep\n",
    "\n",
    "# Drop duplicates to avoid having repeated rows during merge\n",
    "testPhase_unique_df = testPhase_df[additional_columns].drop_duplicates(subset=['deepeye_id', 'trialNr'])\n",
    "\n",
    "# Merge the novelty dataframe with additional information\n",
    "novelty_df = novelty_df.merge(testPhase_unique_df, on=['deepeye_id', 'trialNr'], how='left')\n",
    "\n",
    "# Save the output file\n",
    "novelty_df.to_csv(os.path.join(path_to_analysis, 'allSubjects_NoveltyIndex.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of novelty index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out excluded participants\n",
    "# '2024_01_15_14_19_20' was the second time, '2024_01_26_17_16_28' too few frames, '2024_01_15_11_44_18' & '2024_01_26_13_09_05'keep fixating the center, \n",
    "novelty_df = novelty_df[~novelty_df['deepeye_id'].isin(['2024_01_15_14_19_20', '2024_01_26_17_16_28', '2024_01_15_11_44_18', '2024_01_26_13_09_05'])]\n",
    "\n",
    "total_count = novelty_df.groupby(['deepeye_id']).noveltyIdx_fixCountProp.count()\n",
    "fixCountProp = novelty_df.groupby(['deepeye_id']).noveltyIdx_fixCountProp.mean()\n",
    "fixDurProp = novelty_df.groupby(['deepeye_id']).noveltyIdx_fixDurProp.mean()\n",
    "\n",
    "print(total_count)\n",
    "print(fixCountProp)\n",
    "print(fixDurProp)\n",
    "print(fixCountProp.mean())\n",
    "print(fixDurProp.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
