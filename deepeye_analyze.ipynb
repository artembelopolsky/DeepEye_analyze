{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef424bc5",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f9edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import astropy.convolution as krn\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b492b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHeat(screenRes, xPos, yPos):\n",
    "        xMax = screenRes[0]\n",
    "        yMax = screenRes[1]\n",
    "        xMin = 0\n",
    "        yMin = 0\n",
    "        kernelPar = 50\n",
    "\n",
    "        # Input handeling\n",
    "        xlim = np.logical_and(xPos < xMax, xPos > xMin)\n",
    "        ylim = np.logical_and(yPos < yMax, yPos > yMin)\n",
    "        xyLim = np.logical_and(xlim, ylim)\n",
    "        dataX = xPos[xyLim]\n",
    "        dataX = np.floor(dataX)\n",
    "        dataY = yPos[xyLim]\n",
    "        dataY = np.floor(dataY)\n",
    "\n",
    "        # initiate map and gauskernel\n",
    "        gazeMap = np.zeros([int((xMax-xMin)),int((yMax-yMin))])+0.0001\n",
    "        gausKernel = krn.Gaussian2DKernel(kernelPar)\n",
    "\n",
    "        # Rescale the position vectors (if xmin or ymin != 0)\n",
    "        dataX -= xMin\n",
    "        dataY -= yMin\n",
    "\n",
    "        # Now extract all the unique positions and number of samples\n",
    "        xy = np.vstack((dataX, dataY)).T\n",
    "        uniqueXY, idx, counts = uniqueRows(xy)\n",
    "        uniqueXY = uniqueXY.astype(int)\n",
    "        # populate the gazeMap\n",
    "        gazeMap[uniqueXY[:,0], uniqueXY[:,1]] = counts\n",
    "\n",
    "        # Convolve the gaze with the gauskernel\n",
    "        heatMap = np.transpose(krn.convolve_fft(gazeMap,gausKernel))\n",
    "        heatMap = heatMap/np.max(heatMap)\n",
    "\n",
    "        return heatMap\n",
    "\n",
    "def uniqueRows(x):\n",
    "    y = np.ascontiguousarray(x).view(np.dtype((np.void, x.dtype.itemsize * x.shape[1])))\n",
    "    _, idx, counts = np.unique(y, return_index=True, return_counts = True)\n",
    "    uniques = x[idx]\n",
    "    return uniques, idx, counts\n",
    "\n",
    "\n",
    "def np_euclidean_distance(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.sqrt(np.sum(np.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def dot_error(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    eucl_dist = np_euclidean_distance(y_true, y_pred)\n",
    "    # Get indices of unique dot positions\n",
    "    u, indices = np.unique(y_true, axis=0, return_inverse=True)\n",
    "    # Make dataframe for each sample of unique dot label and error distance\n",
    "    df_dict = {'unique_dot': indices, 'eucl_distance': eucl_dist, 'true_x': y_true[:,0],\n",
    "                'true_y': y_true[:,1], 'pred_x': y_pred[:,0], 'pred_y': y_pred[:,1]}\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    # Group by unique dot position, compute median error per dot, average across dots\n",
    "    mean_dot_error = df.groupby('unique_dot').eucl_distance.median().mean()\n",
    "    std_dot_error = df.groupby('unique_dot').eucl_distance.median().std()\n",
    "\n",
    "    return float(mean_dot_error), df, float(std_dot_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e6abccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last: 13\n",
      "last: 9\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 9\n",
      "last: 13\n",
      "last: 9\n",
      "last: 13\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n",
      "last: 9\n",
      "last: 13\n",
      "last: 13\n",
      "last: 9\n"
     ]
    }
   ],
   "source": [
    "path_to_folders = 'C:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/online/complete'\n",
    "# path_to_folders = 'D:/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/online'\n",
    "\n",
    "# get all folder names\n",
    "folder_names = os.listdir(path_to_folders)\n",
    "\n",
    "pp_list = []\n",
    "for fn in folder_names:\n",
    "    path = os.path.join(path_to_folders, fn, fn+'_test_all.csv')       \n",
    "        \n",
    "    df = pd.read_csv(path)\n",
    "        \n",
    "    \n",
    "    # Find the headers via duplicates and use it to split into datasets\n",
    "    # Make indices of datasets\n",
    "    mask_dup = df.duplicated(keep=False)\n",
    "    idx_dup = df.index[mask_dup == True].tolist()\n",
    "    idx_dup[:0] = [-1] # add lower index\n",
    "    idx_dup.extend([df.shape[0]]) # add upper index\n",
    "    \n",
    "    # Use indices to parse datasets\n",
    "    df_list = []\n",
    "    count_datasets = 0\n",
    "    last_numCalibDots = []\n",
    "    for i in range(len(idx_dup)):\n",
    "        if i < len(idx_dup) - 1:\n",
    "            a = df.iloc[idx_dup[i]+1:idx_dup[i+1]]\n",
    "            a = a.apply(pd.to_numeric, errors='ignore') # when header is written twice, some floats are str, fix this \n",
    "            a['dataset_num'] = count_datasets\n",
    "            a['eucl_dist_px_orig'] = np_euclidean_distance(np.array(a[['x','y']]), np.array(a[['user_pred_px_x','user_pred_px_y']]))\n",
    "            scale_cm_in_px = a.scrW_cm/a.resX\n",
    "            a['eucl_dist_cm_orig'] = a.eucl_dist_px_orig * scale_cm_in_px \n",
    "            \n",
    "            if pd.api.types.is_string_dtype(a.sona_pp_id) == True:\n",
    "                a['platform'] = 'PROLIFIC'\n",
    "            else:\n",
    "                a['platform'] = 'SONA'\n",
    "           \n",
    "            # Label 25-dot conditions based on preceeding dataset\n",
    "            if a.numCalibDots.iloc[0] == 25:\n",
    "                print(f'last: {last_numCalibDots[-1]}')\n",
    "                if last_numCalibDots[-1] == 9:\n",
    "                    a['condition'] = '25_9'\n",
    "                elif last_numCalibDots[-1] == 13:\n",
    "                    a['condition'] = '25_13'\n",
    "                \n",
    "            else:\n",
    "                a['condition'] = a.numCalibDots.astype(str)\n",
    "                \n",
    "            last_numCalibDots.append(a.numCalibDots.iloc[-1]) # log last value                \n",
    "            \n",
    "            # Accumulate all dataset per subject\n",
    "            df_list.append(a)\n",
    "            count_datasets += 1\n",
    "    \n",
    "    \n",
    "    # if there are more than 4 datasets, remove the recalibrated ones, pick the last one\n",
    "    last_numCalibDots = pd.Series(last_numCalibDots)\n",
    "    idx_good_datasets = last_numCalibDots.loc[last_numCalibDots.shift(-1) != last_numCalibDots] # shift dataset by one row and get indices\n",
    "    df_list = [df_list[i] for i in list(idx_good_datasets.index)] # pick only the 4 datasets\n",
    "    assert(len(df_list) == 4)\n",
    "    \n",
    "    # Concatenate all datasets per subject\n",
    "    b = pd.concat(df_list)\n",
    "    \n",
    "    # Add a subj_nr column\n",
    "    b['subj_nr'] = fn    \n",
    "    \n",
    "    # Accumulate datasets across subjects\n",
    "    pp_list.append(b)\n",
    "\n",
    "# Concatenate all subjects in one df\n",
    "df_all = pd.concat(pp_list)\n",
    "\n",
    "\n",
    "\n",
    "# Every display resolution is scaled to this one since all dots are drawn in % display size in px\n",
    "target_resX = 1280.0\n",
    "target_resY = 800.0    \n",
    "\n",
    "# To do:\n",
    "# How many attempts\n",
    "# Filter out failed last attemtps\n",
    "# How to deal with missing data for some dots (e.g. for '2023_04_13_13_53_28')\n",
    "\n",
    "df_all = df_all.reset_index()\n",
    "\n",
    "\n",
    "# Select subset\n",
    "\"\"\"\n",
    "\n",
    "'2023_04_15_11_42_39' - amazing performance, but did not do 25_9\n",
    "\"\"\"\n",
    "# df_all = df_all[df_all.numCalibDots == 9]\n",
    "# df_all = df_all[(df_all.subj_nr == '2023_04_15_12_22_19')]\n",
    "# Exclude subjects\n",
    "df_all = df_all[df_all.subj_nr != '2023_04_07_13_59_57'] # my pilot data\n",
    "df_all = df_all[df_all.subj_nr != '2023_04_07_13_45_47'] # my pilot data\n",
    "\n",
    "\n",
    "# user_predictions_px = np.array(df_all[['user_pred_px_x', 'user_pred_px_y']])\n",
    "df_all['user_pred_px_x_scaled'] = df_all.user_pred_px_x/df_all.resX * target_resX\n",
    "df_all['user_pred_px_y_scaled'] = df_all.user_pred_px_y/df_all.resY * target_resY\n",
    "# ground_truths_px = np.array(df_all[['x','y']])\n",
    "df_all['x_scaled'] = np.round(df_all.x/df_all.resX * target_resX)\n",
    "df_all['y_scaled'] = np.round(df_all.y/df_all.resY * target_resY)\n",
    "\n",
    "df_all['scale_cm_in_px'] = df_all.scrW_cm.astype(float)/df_all.resX.astype(float)\n",
    "scale_cm_in_px = df_all.scale_cm_in_px.mean() # average scaling factor\n",
    "# scale_cm_in_px = df_all.scrW_cm.astype(float)[0]/df_all.resX.astype(float)[0]  \n",
    "\n",
    "# Get indices of unique dot positions (unique rows)\n",
    "u, indices = np.unique(np.array([df_all.x_scaled, df_all.y_scaled]).T, axis=0, return_inverse=True)\n",
    "df_all['unique_dot'] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fab6858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum offset is: (2.5723908273220304, 14    2023_04_13_18_25_35\n",
      "Name: subj_nr, dtype: object)\n",
      "\n",
      "Mean offset:\n",
      "                subj_nr  offset_cm\n",
      "0   2023_04_12_11_19_28   1.111627\n",
      "1   2023_04_12_12_14_51   1.782335\n",
      "2   2023_04_12_13_00_41   1.553751\n",
      "3   2023_04_12_13_20_33   1.895637\n",
      "4   2023_04_12_21_03_47   1.699054\n",
      "5   2023_04_12_21_07_32   1.013709\n",
      "6   2023_04_12_23_30_03   0.945613\n",
      "7   2023_04_13_07_33_30   1.777390\n",
      "8   2023_04_13_08_53_13   1.730888\n",
      "9   2023_04_13_09_27_35   1.154181\n",
      "10  2023_04_13_13_32_18   1.233027\n",
      "11  2023_04_13_13_53_28   2.274451\n",
      "12  2023_04_13_14_57_48   2.226403\n",
      "13  2023_04_13_17_54_55   1.131968\n",
      "14  2023_04_13_18_25_35   2.572391\n",
      "15  2023_04_13_19_29_32   1.800768\n",
      "16  2023_04_13_20_23_24   1.774295\n",
      "17  2023_04_13_20_46_16   0.811727\n",
      "18  2023_04_13_21_04_58   1.660197\n",
      "19  2023_04_13_21_32_06   0.851520\n",
      "20  2023_04_14_11_18_47   2.091864\n",
      "21  2023_04_14_12_03_32   1.632563\n",
      "22  2023_04_14_13_51_14   1.496785\n",
      "23  2023_04_14_14_52_27   2.078053\n",
      "24  2023_04_14_17_12_17   1.025999\n",
      "25  2023_04_14_21_04_57   2.562017\n",
      "26  2023_04_15_11_58_10   1.088461\n",
      "27  2023_04_15_12_22_19   0.957296\n",
      "28  2023_04_15_12_50_43   1.684346\n",
      "29  2023_04_15_13_46_39   0.841580\n",
      "\n",
      "Standard deviation:\n",
      "                subj_nr  eucl_dist_gaze_to_median_cm\n",
      "0   2023_04_12_11_19_28                     0.440951\n",
      "1   2023_04_12_12_14_51                     0.956635\n",
      "2   2023_04_12_13_00_41                     0.812986\n",
      "3   2023_04_12_13_20_33                     1.055800\n",
      "4   2023_04_12_21_03_47                     1.618648\n",
      "5   2023_04_12_21_07_32                     1.023846\n",
      "6   2023_04_12_23_30_03                     0.688515\n",
      "7   2023_04_13_07_33_30                     0.874870\n",
      "8   2023_04_13_08_53_13                     0.506206\n",
      "9   2023_04_13_09_27_35                     0.522708\n",
      "10  2023_04_13_13_32_18                     1.192696\n",
      "11  2023_04_13_13_53_28                     0.614050\n",
      "12  2023_04_13_14_57_48                     1.455395\n",
      "13  2023_04_13_17_54_55                     0.677047\n",
      "14  2023_04_13_18_25_35                     0.668691\n",
      "15  2023_04_13_19_29_32                     0.449677\n",
      "16  2023_04_13_20_23_24                     0.655856\n",
      "17  2023_04_13_20_46_16                     0.416260\n",
      "18  2023_04_13_21_04_58                     0.828823\n",
      "19  2023_04_13_21_32_06                     0.826434\n",
      "20  2023_04_14_11_18_47                     0.958076\n",
      "21  2023_04_14_12_03_32                     1.442272\n",
      "22  2023_04_14_13_51_14                     1.001949\n",
      "23  2023_04_14_14_52_27                     1.113582\n",
      "24  2023_04_14_17_12_17                     0.572492\n",
      "25  2023_04_14_21_04_57                     0.595045\n",
      "26  2023_04_15_11_58_10                     0.433833\n",
      "27  2023_04_15_12_22_19                     0.378601\n",
      "28  2023_04_15_12_50_43                     1.286833\n",
      "29  2023_04_15_13_46_39                     0.582871\n",
      "Maximum offset is: (3.2569838451111712, 9    2023_04_13_09_27_35\n",
      "Name: subj_nr, dtype: object)\n",
      "\n",
      "Mean offset:\n",
      "                subj_nr  offset_cm\n",
      "0   2023_04_12_11_19_28   1.098817\n",
      "1   2023_04_12_12_14_51   2.655491\n",
      "2   2023_04_12_13_00_41   2.957654\n",
      "3   2023_04_12_13_20_33   1.978752\n",
      "4   2023_04_12_21_03_47   1.919591\n",
      "5   2023_04_12_21_07_32   2.040639\n",
      "6   2023_04_12_23_30_03   0.962704\n",
      "7   2023_04_13_07_33_30   2.063736\n",
      "8   2023_04_13_08_53_13   1.140880\n",
      "9   2023_04_13_09_27_35   3.256984\n",
      "10  2023_04_13_13_32_18   2.219167\n",
      "11  2023_04_13_13_53_28   2.271322\n",
      "12  2023_04_13_14_57_48   2.521338\n",
      "13  2023_04_13_17_54_55   0.958782\n",
      "14  2023_04_13_18_25_35   2.804895\n",
      "15  2023_04_13_19_29_32   2.094430\n",
      "16  2023_04_13_20_23_24   2.387624\n",
      "17  2023_04_13_20_46_16   0.605057\n",
      "18  2023_04_13_21_04_58   0.893244\n",
      "19  2023_04_13_21_32_06   1.129206\n",
      "20  2023_04_14_11_18_47   2.932180\n",
      "21  2023_04_14_12_03_32   2.242444\n",
      "22  2023_04_14_13_51_14   1.116859\n",
      "23  2023_04_14_14_52_27   2.143945\n",
      "24  2023_04_14_17_12_17   1.717706\n",
      "25  2023_04_14_21_04_57   1.957764\n",
      "26  2023_04_15_11_58_10   1.171300\n",
      "27  2023_04_15_12_22_19   1.482056\n",
      "28  2023_04_15_12_50_43   0.838585\n",
      "29  2023_04_15_13_46_39   1.127205\n",
      "\n",
      "Standard deviation:\n",
      "                subj_nr  eucl_dist_gaze_to_median_cm\n",
      "0   2023_04_12_11_19_28                     0.418534\n",
      "1   2023_04_12_12_14_51                     0.622891\n",
      "2   2023_04_12_13_00_41                     0.857661\n",
      "3   2023_04_12_13_20_33                     0.560749\n",
      "4   2023_04_12_21_03_47                     1.544172\n",
      "5   2023_04_12_21_07_32                     0.927749\n",
      "6   2023_04_12_23_30_03                     0.620519\n",
      "7   2023_04_13_07_33_30                     0.889956\n",
      "8   2023_04_13_08_53_13                     0.571395\n",
      "9   2023_04_13_09_27_35                     0.420398\n",
      "10  2023_04_13_13_32_18                     1.105550\n",
      "11  2023_04_13_13_53_28                     0.776547\n",
      "12  2023_04_13_14_57_48                     0.946574\n",
      "13  2023_04_13_17_54_55                     0.576719\n",
      "14  2023_04_13_18_25_35                     0.677373\n",
      "15  2023_04_13_19_29_32                     0.723341\n",
      "16  2023_04_13_20_23_24                     0.708494\n",
      "17  2023_04_13_20_46_16                     0.424225\n",
      "18  2023_04_13_21_04_58                     0.588635\n",
      "19  2023_04_13_21_32_06                     0.758076\n",
      "20  2023_04_14_11_18_47                     1.289524\n",
      "21  2023_04_14_12_03_32                     0.895344\n",
      "22  2023_04_14_13_51_14                     0.929518\n",
      "23  2023_04_14_14_52_27                     0.976988\n",
      "24  2023_04_14_17_12_17                     0.582880\n",
      "25  2023_04_14_21_04_57                     0.684312\n",
      "26  2023_04_15_11_58_10                     0.463215\n",
      "27  2023_04_15_12_22_19                     0.477957\n",
      "28  2023_04_15_12_50_43                     1.346291\n",
      "29  2023_04_15_13_46_39                     0.672378\n",
      "Maximum offset is: (3.1370828425565467, 18    2023_04_13_21_04_58\n",
      "Name: subj_nr, dtype: object)\n",
      "\n",
      "Mean offset:\n",
      "                subj_nr  offset_cm\n",
      "0   2023_04_12_11_19_28   1.579280\n",
      "1   2023_04_12_12_14_51   1.752017\n",
      "2   2023_04_12_13_00_41   1.698578\n",
      "3   2023_04_12_13_20_33   1.608646\n",
      "4   2023_04_12_21_03_47   2.926704\n",
      "5   2023_04_12_21_07_32   1.094047\n",
      "6   2023_04_12_23_30_03   1.486720\n",
      "7   2023_04_13_07_33_30   1.453532\n",
      "8   2023_04_13_08_53_13   1.641130\n",
      "9   2023_04_13_09_27_35   1.118833\n",
      "10  2023_04_13_13_32_18   2.239538\n",
      "11  2023_04_13_13_53_28   1.813636\n",
      "12  2023_04_13_14_57_48   1.716064\n",
      "13  2023_04_13_17_54_55   2.839717\n",
      "14  2023_04_13_18_25_35   0.746923\n",
      "15  2023_04_13_19_29_32   1.748132\n",
      "16  2023_04_13_20_23_24   1.599480\n",
      "17  2023_04_13_20_46_16   1.281699\n",
      "18  2023_04_13_21_04_58   3.137083\n",
      "19  2023_04_13_21_32_06   1.544946\n",
      "20  2023_04_14_11_18_47   1.812449\n",
      "21  2023_04_14_12_03_32   1.837581\n",
      "22  2023_04_14_13_51_14   1.644821\n",
      "23  2023_04_14_14_52_27   2.422264\n",
      "24  2023_04_14_17_12_17   1.969964\n",
      "25  2023_04_14_21_04_57   2.097044\n",
      "26  2023_04_15_11_58_10   1.847795\n",
      "27  2023_04_15_12_22_19   1.754099\n",
      "28  2023_04_15_12_50_43   1.866340\n",
      "29  2023_04_15_13_46_39   0.997299\n",
      "\n",
      "Standard deviation:\n",
      "                subj_nr  eucl_dist_gaze_to_median_cm\n",
      "0   2023_04_12_11_19_28                     0.432350\n",
      "1   2023_04_12_12_14_51                     0.892338\n",
      "2   2023_04_12_13_00_41                     0.846537\n",
      "3   2023_04_12_13_20_33                     0.630637\n",
      "4   2023_04_12_21_03_47                     1.811806\n",
      "5   2023_04_12_21_07_32                     0.798844\n",
      "6   2023_04_12_23_30_03                     0.574018\n",
      "7   2023_04_13_07_33_30                     0.754912\n",
      "8   2023_04_13_08_53_13                     0.784768\n",
      "9   2023_04_13_09_27_35                     0.319776\n",
      "10  2023_04_13_13_32_18                     1.358048\n",
      "11  2023_04_13_13_53_28                     0.586483\n",
      "12  2023_04_13_14_57_48                     1.100076\n",
      "13  2023_04_13_17_54_55                     0.422484\n",
      "14  2023_04_13_18_25_35                     0.601939\n",
      "15  2023_04_13_19_29_32                     0.521557\n",
      "16  2023_04_13_20_23_24                     0.857363\n",
      "17  2023_04_13_20_46_16                     0.491949\n",
      "18  2023_04_13_21_04_58                     0.571551\n",
      "19  2023_04_13_21_32_06                     0.871018\n",
      "20  2023_04_14_11_18_47                     1.341437\n",
      "21  2023_04_14_12_03_32                     0.906976\n",
      "22  2023_04_14_13_51_14                     1.028277\n",
      "23  2023_04_14_14_52_27                     0.689181\n",
      "24  2023_04_14_17_12_17                     0.605676\n",
      "25  2023_04_14_21_04_57                     0.802328\n",
      "26  2023_04_15_11_58_10                     0.520847\n",
      "27  2023_04_15_12_22_19                     0.497884\n",
      "28  2023_04_15_12_50_43                     1.238164\n",
      "29  2023_04_15_13_46_39                     1.051321\n",
      "Maximum offset is: (2.4153974606002873, 18    2023_04_13_21_04_58\n",
      "Name: subj_nr, dtype: object)\n",
      "\n",
      "Mean offset:\n",
      "                subj_nr  offset_cm\n",
      "0   2023_04_12_11_19_28   0.960500\n",
      "1   2023_04_12_12_14_51   1.428994\n",
      "2   2023_04_12_13_00_41   1.041549\n",
      "3   2023_04_12_13_20_33   1.103684\n",
      "4   2023_04_12_21_03_47   2.174139\n",
      "5   2023_04_12_21_07_32   0.848555\n",
      "6   2023_04_12_23_30_03   0.795352\n",
      "7   2023_04_13_07_33_30   0.914568\n",
      "8   2023_04_13_08_53_13   1.192940\n",
      "9   2023_04_13_09_27_35   0.878190\n",
      "10  2023_04_13_13_32_18   1.143508\n",
      "11  2023_04_13_13_53_28   0.522922\n",
      "12  2023_04_13_14_57_48   2.090144\n",
      "13  2023_04_13_17_54_55   2.043106\n",
      "14  2023_04_13_18_25_35   0.436812\n",
      "15  2023_04_13_19_29_32   1.054671\n",
      "16  2023_04_13_20_23_24   1.409981\n",
      "17  2023_04_13_20_46_16   0.806032\n",
      "18  2023_04_13_21_04_58   2.415397\n",
      "19  2023_04_13_21_32_06   0.756717\n",
      "20  2023_04_14_11_18_47   1.293415\n",
      "21  2023_04_14_12_03_32   0.315652\n",
      "22  2023_04_14_13_51_14   0.640460\n",
      "23  2023_04_14_14_52_27   2.390221\n",
      "24  2023_04_14_17_12_17   0.492963\n",
      "25  2023_04_14_21_04_57   1.497205\n",
      "26  2023_04_15_11_58_10   1.230844\n",
      "27  2023_04_15_12_22_19   1.685139\n",
      "28  2023_04_15_12_50_43   1.190538\n",
      "29  2023_04_15_13_46_39   0.758893\n",
      "\n",
      "Standard deviation:\n",
      "                subj_nr  eucl_dist_gaze_to_median_cm\n",
      "0   2023_04_12_11_19_28                     0.208034\n",
      "1   2023_04_12_12_14_51                     0.822454\n",
      "2   2023_04_12_13_00_41                     0.563123\n",
      "3   2023_04_12_13_20_33                     0.605546\n",
      "4   2023_04_12_21_03_47                     1.766578\n",
      "5   2023_04_12_21_07_32                     0.578290\n",
      "6   2023_04_12_23_30_03                     0.709029\n",
      "7   2023_04_13_07_33_30                     0.703526\n",
      "8   2023_04_13_08_53_13                     0.424421\n",
      "9   2023_04_13_09_27_35                     0.291730\n",
      "10  2023_04_13_13_32_18                     1.022981\n",
      "11  2023_04_13_13_53_28                     0.464687\n",
      "12  2023_04_13_14_57_48                     1.013567\n",
      "13  2023_04_13_17_54_55                     0.450125\n",
      "14  2023_04_13_18_25_35                     0.748355\n",
      "15  2023_04_13_19_29_32                     0.525950\n",
      "16  2023_04_13_20_23_24                     0.713765\n",
      "17  2023_04_13_20_46_16                     0.647995\n",
      "18  2023_04_13_21_04_58                     0.889989\n",
      "19  2023_04_13_21_32_06                     0.634889\n",
      "20  2023_04_14_11_18_47                     1.714086\n",
      "21  2023_04_14_12_03_32                     0.847902\n",
      "22  2023_04_14_13_51_14                     0.698939\n",
      "23  2023_04_14_14_52_27                     0.511587\n",
      "24  2023_04_14_17_12_17                     0.517248\n",
      "25  2023_04_14_21_04_57                     0.676867\n",
      "26  2023_04_15_11_58_10                     0.650181\n",
      "27  2023_04_15_12_22_19                     0.493421\n",
      "28  2023_04_15_12_50_43                     1.233507\n",
      "29  2023_04_15_13_46_39                     0.568011\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plotting mean E.d. and SD per condition\n",
    "\"\"\"\n",
    "\n",
    "# df_all = df_all[df_all.condition == '9']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=4)\n",
    "fig.set_size_inches((8.5, 11), forward=False)\n",
    "\n",
    "\n",
    "# Loop thru each condition\n",
    "count_plots = 0\n",
    "summary_df_all = []\n",
    "\n",
    "for name, i in df_all.groupby('condition'):\n",
    "    \n",
    "    summary_df = []    \n",
    "   \n",
    "    # Loop thru each subject and unique dot\n",
    "    for _, j in i.groupby(['subj_nr', 'unique_dot']):\n",
    "        \n",
    "        # Get median gaze for each unique dot in pixels\n",
    "        j['median_pred_x'] = j.user_pred_px_x_scaled.median()\n",
    "        j['median_pred_y'] = j.user_pred_px_y_scaled.median()\n",
    "        \n",
    "        # Get euclidean distance from each gaze sample to median gaze for each dot\n",
    "        j['eucl_dist_gaze_to_median_px'] = np_euclidean_distance(np.array([j.user_pred_px_x_scaled, j.user_pred_px_y_scaled]).T, \n",
    "                              np.array([j.median_pred_x, j.median_pred_y]).T)        \n",
    "        j['eucl_dist_gaze_to_median_cm'] = j.eucl_dist_gaze_to_median_px * scale_cm_in_px\n",
    "        \n",
    "        # Get euclidean distance from median gaze to ground truth (accuracy)\n",
    "        j['offset_px'] = np_euclidean_distance(np.array([j.median_pred_x, j.median_pred_y]).T, np.array([j.x_scaled, j.y_scaled]).T)  \n",
    "        j['offset_cm'] = j.offset_px * scale_cm_in_px\n",
    "        \n",
    "        summary_df.append(j)\n",
    "        \n",
    "      \n",
    "    summary_df = pd.concat(summary_df)\n",
    "    \n",
    "    # Get STD (mean distance of gaze_to_median per subject)\n",
    "    agg_SD = summary_df.groupby(['subj_nr'])[['eucl_dist_gaze_to_median_cm']].mean().reset_index()\n",
    "    \n",
    "    # Get accuracy\n",
    "    agg_OFFSET = summary_df.groupby(['subj_nr'])[['offset_cm']].mean().reset_index()\n",
    "      \n",
    "        \n",
    "    \n",
    "    # Get subj nr for the largest error\n",
    "    max_offset_subj = agg_OFFSET.where(agg_OFFSET.offset_cm==agg_OFFSET.offset_cm.max()).dropna().subj_nr\n",
    "    print(f'Maximum offset is: {agg_OFFSET.offset_cm.max(), max_offset_subj}')\n",
    "    print('\\nMean offset:')\n",
    "    print(agg_OFFSET.mean())\n",
    "    print('\\nStandard deviation:')\n",
    "    print(agg_SD.mean())\n",
    "    \n",
    "    # Plot euclidean distances per subject\n",
    "    ax[0, count_plots].title.set_text(f'Condition:{i.condition.iloc[0]}\\nOffset')\n",
    "    ax[0, count_plots].set_ylim(0,4.5)\n",
    "    ax[0, count_plots].scatter(np.ones(agg_OFFSET.offset_cm.size),agg_OFFSET.offset_cm)\n",
    "    ax[0, count_plots].scatter(1,agg_OFFSET.offset_cm.mean())\n",
    "    \n",
    "    # Plot SD per subject\n",
    "    ax[1, count_plots].title.set_text(f'Condition:{i.condition.iloc[0]}\\nSD')\n",
    "    ax[1, count_plots].set_ylim(0,4.5)\n",
    "    ax[1, count_plots].scatter(np.ones(agg_SD.eucl_dist_gaze_to_median_cm.size),agg_SD.eucl_dist_gaze_to_median_cm)\n",
    "    ax[1, count_plots].scatter(1,agg_SD.eucl_dist_gaze_to_median_cm.mean())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    count_plots += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0641e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
