{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "740f3de2",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "93f8e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import astropy.convolution as krn\n",
    "import scipy.stats as stats\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a8797d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHeat(screenRes, xPos, yPos):\n",
    "        xMax = screenRes[0]\n",
    "        yMax = screenRes[1]\n",
    "        xMin = 0\n",
    "        yMin = 0\n",
    "        kernelPar = 50\n",
    "\n",
    "        # Input handeling\n",
    "        xlim = np.logical_and(xPos < xMax, xPos > xMin)\n",
    "        ylim = np.logical_and(yPos < yMax, yPos > yMin)\n",
    "        xyLim = np.logical_and(xlim, ylim)\n",
    "        dataX = xPos[xyLim]\n",
    "        dataX = np.floor(dataX)\n",
    "        dataY = yPos[xyLim]\n",
    "        dataY = np.floor(dataY)\n",
    "\n",
    "        # initiate map and gauskernel\n",
    "        gazeMap = np.zeros([int((xMax-xMin)),int((yMax-yMin))])+0.0001\n",
    "        gausKernel = krn.Gaussian2DKernel(kernelPar)\n",
    "\n",
    "        # Rescale the position vectors (if xmin or ymin != 0)\n",
    "        dataX -= xMin\n",
    "        dataY -= yMin\n",
    "\n",
    "        # Now extract all the unique positions and number of samples\n",
    "        xy = np.vstack((dataX, dataY)).T\n",
    "        uniqueXY, idx, counts = uniqueRows(xy)\n",
    "        uniqueXY = uniqueXY.astype(int)\n",
    "        # populate the gazeMap\n",
    "        gazeMap[uniqueXY[:,0], uniqueXY[:,1]] = counts\n",
    "\n",
    "        # Convolve the gaze with the gauskernel\n",
    "        heatMap = np.transpose(krn.convolve_fft(gazeMap,gausKernel))\n",
    "        heatMap = heatMap/np.max(heatMap)\n",
    "\n",
    "        return heatMap\n",
    "\n",
    "def uniqueRows(x):\n",
    "    y = np.ascontiguousarray(x).view(np.dtype((np.void, x.dtype.itemsize * x.shape[1])))\n",
    "    _, idx, counts = np.unique(y, return_index=True, return_counts = True)\n",
    "    uniques = x[idx]\n",
    "    return uniques, idx, counts\n",
    "\n",
    "\n",
    "def np_euclidean_distance(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.sqrt(np.sum(np.square(y_pred - y_true), axis=-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9c5ec",
   "metadata": {},
   "source": [
    "### Preprocess, extract fixations and add them to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db18a3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Importing and processing: \"C:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_MullerLyer\\2023_06_27_08_39_36\\2023_06_27_08_39_36_record.csv\"\n",
      "\tSearching for valid interpolation windows\n",
      "\tReplace interpolation windows with Steffen interpolation\n",
      "\t2-Means clustering started for averaged signal\n",
      "\tDetermining fixations based on clustering weight mean for averaged signal and separate eyes + 2*std\n",
      "\n",
      "\n",
      "I2MC took 3.898467779159546s to finish!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\envs\\default\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "C:\\Users\\artem\\anaconda3\\envs\\default\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./FixationDetection')\n",
    "from I2MC import runI2MC\n",
    "\n",
    "# Path to data folders\n",
    "path_to_folders = 'C:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_MullerLyer'\n",
    "# path_to_folders = 'D:/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/online/complete'\n",
    "\n",
    "# get all folder names\n",
    "folder_names = os.listdir(path_to_folders)\n",
    "\n",
    "# read and process original datafile for each participant\n",
    "for fn in folder_names:\n",
    "    path = os.path.join(path_to_folders, fn, fn+'_record.csv')       \n",
    "        \n",
    "    df = pd.read_csv(path)        \n",
    "\n",
    "# order frames and drop duplicate xs,ys\n",
    "df = df.sort_values('frameNr')\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop_duplicates(subset=['user_pred_px_x', 'user_pred_px_y'], ignore_index=True)\n",
    "\n",
    "# get fixations for the original datafile for each participant\n",
    "fixDF = runI2MC(path, plotData = False)\n",
    "\n",
    "# add extracted fixations to the original data file (two new columns)\n",
    "# for each timestamp where fixation was detected, FixXPos and FixYPos are added\n",
    "idx = 0 # index of fixDF\n",
    "FixXPos = np.zeros(df.shape[0])\n",
    "FixYPos = np.zeros(df.shape[0])\n",
    "\n",
    "# iterate thru the original dataframe, thru each sample\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # make sure not to iterate out of range\n",
    "    if idx < fixDF.shape[0]:\n",
    "        \n",
    "        # go to next fixation when fixation ends\n",
    "        if row['sampTime'] >= np.array(fixDF.FixEnd)[idx]:\n",
    "                idx += 1\n",
    "        \n",
    "        # make sure not to iterate out of range\n",
    "        if idx < fixDF.shape[0]:\n",
    "            \n",
    "            # when samples are within fixation, accumulate FixXPos and FixYPos\n",
    "            if row['sampTime'] >= np.array(fixDF.FixStart)[idx] and row['sampTime'] <= np.array(fixDF.FixEnd)[idx]:\n",
    "\n",
    "                FixXPos[index] = (np.array(fixDF.XPos)[idx])\n",
    "                FixYPos[index] = (np.array(fixDF.YPos)[idx])\n",
    "       \n",
    "\n",
    " \n",
    "# add fixations to original dataframe\n",
    "df['FixXPos'] = np.array(FixXPos)\n",
    "df['FixYPos'] = np.array(FixYPos)\n",
    "\n",
    "\n",
    "# Extract only samples when the target was presented\n",
    "df = df[df.event=='target_on']\n",
    "\n",
    "# Remove samples with no fixations\n",
    "df = df[(df.FixXPos!=0) & (df.FixYPos!=0)]\n",
    "\n",
    "# Get only frames when fixation starts\n",
    "df = df.drop_duplicates(subset=['FixXPos', 'FixYPos'], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be0fcee",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4d8cbed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min distance to target in pixes\n",
    "pix_in_cm = df.resX[0]/df.scrW_cm[0]\n",
    "minDistTarg = pix_in_cm * 3\n",
    "\n",
    "# Get dataframe with targets on the left (leftward saccades)\n",
    "df_targLeft = df[df.target=='left']\n",
    "\n",
    "# drop fixations that are not within the target on X-axis\n",
    "df_targLeft = df_targLeft[(df_targLeft.FixXPos < (df_targLeft.targetX.iloc[0] + minDistTarg)) &\n",
    "                          (df_targLeft.FixXPos > (df_targLeft.targetX.iloc[0] - minDistTarg))]\n",
    "\n",
    "# Get only the first fixations after target was presented (if more than one fixation present)\n",
    "df_targLeft = df_targLeft.drop_duplicates(subset=['trialNr'],  keep='first', ignore_index=True)\n",
    "\n",
    "# Get dataframe with targets on the right (rightward saccades)\n",
    "df_targRight = df[df.target=='right']\n",
    "\n",
    "# drop fixations that are not within the target on X-axis\n",
    "df_targRight = df_targRight[(df_targRight.FixXPos > (df_targRight.targetX.iloc[0] - minDistTarg)) &\n",
    "                          (df_targRight.FixXPos < (df_targRight.targetX.iloc[0] + minDistTarg))]\n",
    "\n",
    "# Get only the first fixations after target was presented (if more than one fixation present)\n",
    "df_targRight = df_targRight.drop_duplicates(subset=['trialNr'],  keep='first', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b29b71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fixations(df, agg='median', title=''):\n",
    "    \n",
    "    out = df[df.condition=='arrowHeadsOutward']\n",
    "    inw = df[df.condition=='arrowHeadsInward']\n",
    "\n",
    "    if agg=='median':\n",
    "        \n",
    "        outX = out.FixXPos.median()\n",
    "        outY = out.FixYPos.median()\n",
    "\n",
    "        inwX = inw.FixXPos.median()\n",
    "        inwY = inw.FixYPos.median()\n",
    "        \n",
    "    elif agg=='mean':\n",
    "        \n",
    "        outX = out.FixXPos.mean()\n",
    "        outY = out.FixYPos.mean()\n",
    "\n",
    "        inwX = inw.FixXPos.mean()\n",
    "        inwY = inw.FixYPos.mean()\n",
    "        \n",
    "        \n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title);\n",
    "    plt.scatter(out.FixXPos, out.FixYPos, c='blue')\n",
    "    plt.scatter(inw.FixXPos, inw.FixYPos, c='orange')\n",
    "    plt.scatter(out.fixationStimX, out.fixationStimY, c='red')\n",
    "    plt.scatter(out.targetX, out.fixationStimY, c='green')\n",
    "\n",
    "    plt.scatter(outX, outY, c='purple')\n",
    "    plt.scatter(inwX, inwY, c='yellow')\n",
    "    \n",
    "    plt.xlim((0, df.resX[0]))\n",
    "    plt.ylim((0, df.resY[0]))\n",
    "\n",
    "    return outX, outY, inwX, inwY\n",
    "\n",
    "\n",
    "# Plot\n",
    "summary_left = plot_fixations(df_targLeft, agg='mean', title='Target Left')\n",
    "summary_right = plot_fixations(df_targRight, agg='mean', title='Target Right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e72cf4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 800.0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98de8a65",
   "metadata": {},
   "source": [
    "### Plot heatmaps per each condition\n",
    "Gaze positions for all subjects are combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4c68c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fixations into output file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce318c36",
   "metadata": {},
   "source": [
    "### To do\n",
    "1. Summarize the incomplete datasets (failed calibration, other reasons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
