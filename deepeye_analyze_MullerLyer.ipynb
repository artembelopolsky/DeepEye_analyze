{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e44b344",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2c8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import astropy.convolution as krn\n",
    "import scipy.stats as stats\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0014a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHeat(screenRes, xPos, yPos):\n",
    "        xMax = screenRes[0]\n",
    "        yMax = screenRes[1]\n",
    "        xMin = 0\n",
    "        yMin = 0\n",
    "        kernelPar = 50\n",
    "\n",
    "        # Input handeling\n",
    "        xlim = np.logical_and(xPos < xMax, xPos > xMin)\n",
    "        ylim = np.logical_and(yPos < yMax, yPos > yMin)\n",
    "        xyLim = np.logical_and(xlim, ylim)\n",
    "        dataX = xPos[xyLim]\n",
    "        dataX = np.floor(dataX)\n",
    "        dataY = yPos[xyLim]\n",
    "        dataY = np.floor(dataY)\n",
    "\n",
    "        # initiate map and gauskernel\n",
    "        gazeMap = np.zeros([int((xMax-xMin)),int((yMax-yMin))])+0.0001\n",
    "        gausKernel = krn.Gaussian2DKernel(kernelPar)\n",
    "\n",
    "        # Rescale the position vectors (if xmin or ymin != 0)\n",
    "        dataX -= xMin\n",
    "        dataY -= yMin\n",
    "\n",
    "        # Now extract all the unique positions and number of samples\n",
    "        xy = np.vstack((dataX, dataY)).T\n",
    "        uniqueXY, idx, counts = uniqueRows(xy)\n",
    "        uniqueXY = uniqueXY.astype(int)\n",
    "        # populate the gazeMap\n",
    "        gazeMap[uniqueXY[:,0], uniqueXY[:,1]] = counts\n",
    "\n",
    "        # Convolve the gaze with the gauskernel\n",
    "        heatMap = np.transpose(krn.convolve_fft(gazeMap,gausKernel))\n",
    "        heatMap = heatMap/np.max(heatMap)\n",
    "\n",
    "        return heatMap\n",
    "\n",
    "def uniqueRows(x):\n",
    "    y = np.ascontiguousarray(x).view(np.dtype((np.void, x.dtype.itemsize * x.shape[1])))\n",
    "    _, idx, counts = np.unique(y, return_index=True, return_counts = True)\n",
    "    uniques = x[idx]\n",
    "    return uniques, idx, counts\n",
    "\n",
    "\n",
    "def np_euclidean_distance(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.sqrt(np.sum(np.square(y_pred - y_true), axis=-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261bc0af",
   "metadata": {},
   "source": [
    "### Preprocess, extract fixations and add them to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "49e6ca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Importing and processing: \"C:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_MullerLyer\\2023_06_27_08_39_36\\2023_06_27_08_39_36_record.csv\"\n",
      "\tSearching for valid interpolation windows\n",
      "\tReplace interpolation windows with Steffen interpolation\n",
      "\t2-Means clustering started for averaged signal\n",
      "\tDetermining fixations based on clustering weight mean for averaged signal and separate eyes + 2*std\n",
      "\n",
      "\n",
      "I2MC took 3.848076820373535s to finish!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\envs\\default\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "C:\\Users\\artem\\anaconda3\\envs\\default\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./FixationDetection')\n",
    "from I2MC import runI2MC\n",
    "\n",
    "# Path to data folders\n",
    "path_to_folders = 'C:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_MullerLyer'\n",
    "# path_to_folders = 'D:/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_MullerLyer'\n",
    "\n",
    "# get all folder names\n",
    "folder_names = os.listdir(path_to_folders)\n",
    "\n",
    "# read and process original datafile for each participant\n",
    "for fn in folder_names:\n",
    "    path = os.path.join(path_to_folders, fn, fn+'_record.csv')       \n",
    "        \n",
    "    df = pd.read_csv(path)        \n",
    "\n",
    "# order frames and drop duplicate samples (with same sampleTime)\n",
    "df = df.sort_values('frameNr')\n",
    "df = df.reset_index(drop=True)\n",
    "# df = df.drop_duplicates(subset=['user_pred_px_x', 'user_pred_px_y'], ignore_index=True)\n",
    "df = df.drop_duplicates(subset=['sampTime'], ignore_index=True)\n",
    "\n",
    "# get fixations for the original datafile for each participant\n",
    "fixDF = runI2MC(path, plotData = False)\n",
    "\n",
    "# add extracted fixations to the original data file (two new columns)\n",
    "# for each timestamp where fixation was detected, FixXPos and FixYPos are added\n",
    "idx = 0 # index of fixDF\n",
    "FixXPos = np.zeros(df.shape[0])\n",
    "FixYPos = np.zeros(df.shape[0])\n",
    "FixStartEnd = np.empty(df.shape[0], dtype='U10')\n",
    "FixStartEnd.fill('') # explicitly fill the array (good practice)\n",
    "\n",
    "DistFromPrevFix = np.zeros(df.shape[0])\n",
    "prev_fix_x = False # keep track of xy when fixation ends\n",
    "prev_fix_y = False\n",
    "\n",
    "PrevFixSampTime = np.zeros(df.shape[0])\n",
    "prev_fix_sampTime = 0\n",
    "\n",
    "# iterate thru the original dataframe, thru each sample\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # make sure not to iterate out of range\n",
    "    if idx < fixDF.shape[0]:\n",
    "        \n",
    "        # go to next fixation when fixation ends\n",
    "        if row['sampTime'] > np.array(fixDF.FixEnd)[idx]:\n",
    "                idx += 1\n",
    "        \n",
    "        # make sure not to iterate out of range\n",
    "        if idx < fixDF.shape[0]:\n",
    "            \n",
    "            # when samples are within fixation, accumulate FixXPos and FixYPos\n",
    "            if row['sampTime'] >= np.array(fixDF.FixStart)[idx] and row['sampTime'] <= np.array(fixDF.FixEnd)[idx]:\n",
    "\n",
    "                FixXPos[index] = (np.array(fixDF.XPos)[idx])\n",
    "                FixYPos[index] = (np.array(fixDF.YPos)[idx])\n",
    "            \n",
    "            # label samples on which fixation starts and ends\n",
    "            if row['sampTime'] == np.array(fixDF.FixStart)[idx]:             \n",
    "                FixStartEnd[index] = 'fix_start'\n",
    "                \n",
    "                if prev_fix_x != False:\n",
    "                    DistFromPrevFix[index] = np.sqrt((np.array(fixDF.XPos)[idx] - prev_fix_x)**2 \n",
    "                                            + (np.array(fixDF.YPos)[idx] - prev_fix_y)**2)\n",
    "                    PrevFixSampTime[index] = prev_fix_sampTime\n",
    "            \n",
    "            elif row['sampTime'] == np.array(fixDF.FixEnd)[idx]:                \n",
    "                FixStartEnd[index] = 'fix_end'             \n",
    "                                    \n",
    "                prev_fix_x = np.array(fixDF.XPos)[idx]\n",
    "                prev_fix_y = np.array(fixDF.YPos)[idx]\n",
    "                prev_fix_sampTime = np.array(row['sampTime'])\n",
    "                \n",
    "       \n",
    "\n",
    " \n",
    "# add fixations to original dataframe\n",
    "df['FixXPos'] = np.array(FixXPos)\n",
    "df['FixYPos'] = np.array(FixYPos)\n",
    "df['FixStartEnd'] = FixStartEnd\n",
    "df['DistFromPrevFix'] = DistFromPrevFix\n",
    "df['PrevFixSampTime'] = PrevFixSampTime\n",
    "\n",
    "\n",
    "# Extract only samples when the target was presented\n",
    "df = df[df.event=='target_on']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "01f8f29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  2.,  3., 20., 41., 18.,  9.,  3.,  0.,  1.]),\n",
       " array([149. , 178.3, 207.6, 236.9, 266.2, 295.5, 324.8, 354.1, 383.4,\n",
       "        412.7, 442. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get saccade latency\n",
    "\n",
    "# get the first sample target is presented\n",
    "b = df.drop_duplicates(subset=['trialNr'],  keep='first', ignore_index=True)\n",
    "# extract the columns needed\n",
    "b = b[['trialNr', 'sampTime']]\n",
    "# rename the columns so they would be added\n",
    "b.columns = ['trialNr', 'targSampTime']\n",
    "# merge the target time into the main df (one time per trial)\n",
    "df = pd.merge(df, b, on=\"trialNr\")\n",
    "\n",
    "# get samples where fixation ended\n",
    "a = df[df.FixStartEnd == 'fix_start']\n",
    "\n",
    "# get samples with large enough preceeding saccade\n",
    "a = a[a.DistFromPrevFix > 300]\n",
    "\n",
    "# computs first fixation duration\n",
    "c = a.PrevFixSampTime - a.targSampTime\n",
    "a['FixDur'] = c\n",
    "# plot first fixation durations (saccade latencies)\n",
    "plt.figure()\n",
    "plt.hist(c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619fb42",
   "metadata": {},
   "source": [
    "### Plot to compare raw samples to fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481c81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a = df[df.target=='right']\n",
    "\n",
    "\n",
    "b = a[a.trialNr==4]\n",
    "c = np.array(b.sampTime)\n",
    "c = c-c[0]\n",
    "plt.figure()\n",
    "plt.scatter(c, b.user_pred_px_x, c='orange')\n",
    "plt.scatter(c, b.FixXPos, c='blue')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(a.user_pred_px_x, a.user_pred_px_y, c='orange')\n",
    "plt.scatter(a.FixXPos, a.FixYPos, c='blue')\n",
    "plt.scatter(a.fixationStimX, a.fixationStimY, c='red')\n",
    "plt.scatter(a.targetX, a.fixationStimY, c='green')\n",
    "\n",
    "plt.xlim((0, a.resX.iloc[0]))\n",
    "plt.ylim((0, a.resY.iloc[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4920593f",
   "metadata": {},
   "source": [
    "### Compare landing position between outward and inward arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06aca356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min distance to target in pixes\n",
    "pix_in_cm = df.resX.iloc[0]/df.scrW_cm.iloc[0]\n",
    "minDistTarg = pix_in_cm * 3\n",
    "\n",
    "# Get dataframe with targets on the left (leftward saccades)\n",
    "df_targLeft = df_fix[df_fix.target=='left']\n",
    "\n",
    "# drop fixations that are not within the target on X-axis\n",
    "df_targLeft = df_targLeft[(df_targLeft.FixXPos < (df_targLeft.targetX.iloc[0] + minDistTarg)) &\n",
    "                          (df_targLeft.FixXPos > (df_targLeft.targetX.iloc[0] - minDistTarg))]\n",
    "\n",
    "# Get only the first fixations after target was presented (if more than one fixation present)\n",
    "df_targLeft = df_targLeft.drop_duplicates(subset=['trialNr'],  keep='first', ignore_index=True)\n",
    "\n",
    "# Get dataframe with targets on the right (rightward saccades)\n",
    "df_targRight = df_fix[df_fix.target=='right']\n",
    "\n",
    "# drop fixations that are not within the target on X-axis\n",
    "df_targRight = df_targRight[(df_targRight.FixXPos > (df_targRight.targetX.iloc[0] - minDistTarg)) &\n",
    "                          (df_targRight.FixXPos < (df_targRight.targetX.iloc[0] + minDistTarg))]\n",
    "\n",
    "# Get only the first fixations after target was presented (if more than one fixation present)\n",
    "df_targRight = df_targRight.drop_duplicates(subset=['trialNr'],  keep='first', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af1c3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fixations(df, agg='median', title=''):\n",
    "    \n",
    "    out = df[df.condition=='arrowHeadsOutward']\n",
    "    inw = df[df.condition=='arrowHeadsInward']\n",
    "\n",
    "    if agg=='median':\n",
    "        \n",
    "        outX = out.FixXPos.median()\n",
    "        outY = out.FixYPos.median()\n",
    "\n",
    "        inwX = inw.FixXPos.median()\n",
    "        inwY = inw.FixYPos.median()\n",
    "        \n",
    "    elif agg=='mean':\n",
    "        \n",
    "        outX = out.FixXPos.mean()\n",
    "        outY = out.FixYPos.mean()\n",
    "\n",
    "        inwX = inw.FixXPos.mean()\n",
    "        inwY = inw.FixYPos.mean()\n",
    "        \n",
    "        \n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title);\n",
    "    plt.scatter(out.FixXPos, out.FixYPos, c='blue')\n",
    "    plt.scatter(inw.FixXPos, inw.FixYPos, c='orange')\n",
    "    plt.scatter(out.fixationStimX, out.fixationStimY, c='red')\n",
    "    plt.scatter(out.targetX, out.fixationStimY, c='green')\n",
    "\n",
    "    plt.scatter(outX, outY, c='purple')\n",
    "    plt.scatter(inwX, inwY, c='yellow')\n",
    "    \n",
    "    plt.xlim((0, df.resX[0]))\n",
    "    plt.ylim((0, df.resY[0]))\n",
    "\n",
    "    return outX, outY, inwX, inwY\n",
    "\n",
    "\n",
    "# Plot\n",
    "summary_left = plot_fixations(df_targLeft, agg='mean', title='Target Left')\n",
    "summary_right = plot_fixations(df_targRight, agg='mean', title='Target Right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0c379c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 800.0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "978a917a",
   "metadata": {},
   "source": [
    "### Plot heatmaps per each condition\n",
    "Gaze positions for all subjects are combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dc7d6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fixations into output file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6594155d",
   "metadata": {},
   "source": [
    "### To do\n",
    "1. Summarize the incomplete datasets (failed calibration, other reasons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
