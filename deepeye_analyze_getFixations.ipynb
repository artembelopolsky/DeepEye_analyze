{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a827ed49",
   "metadata": {},
   "source": [
    "# This notebook is used to extract fixations for each participant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee5373",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a2e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Enable interactive Matplotlib plots in the notebook\n",
    "%matplotlib qt5\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import astropy.convolution as krn\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69aa0a",
   "metadata": {},
   "source": [
    "### Preprocess, extract fixations and add them to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7038f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fixations(df, path):\n",
    "    \n",
    "    sys.path.append('./FixationDetection')\n",
    "    from I2MC import runI2MC\n",
    "    \n",
    "    # order frames and drop duplicate samples (with same sampleTime)\n",
    "    df = df[df.fName.notna()]\n",
    "    df.frameNr = df.frameNr.apply(pd.to_numeric, errors='coerce') # if framerNr is not a number, it is replaces with nan\n",
    "    df = df[df.frameNr.notna()] # filter out rows where frameNr is a nan\n",
    "\n",
    "    df = df[df.sampTime.notna()]\n",
    "    df = df[df.user_pred_px_x.notna()]\n",
    "    df = df[df.user_pred_px_y.notna()]\n",
    "    df = df.apply(pd.to_numeric, errors='ignore') # if str convert str to numbers\n",
    "\n",
    "    df = df.sort_values('frameNr')\n",
    "    df = df.reset_index(drop=True)\n",
    "    # df = df.drop_duplicates(subset=['user_pred_px_x', 'user_pred_px_y'], ignore_index=True)\n",
    "    df = df.drop_duplicates(subset=['sampTime'], ignore_index=True)\n",
    "       \n",
    "    \n",
    "    # get fixations for the original datafile for each participant\n",
    "    fixDF = runI2MC(path, plotData = False)\n",
    "\n",
    "    # add extracted fixations to the original data file (two new columns)\n",
    "    # for each timestamp where fixation was detected, FixXPos and FixYPos are added\n",
    "    idx = 0 # index of fixDF\n",
    "    FixXPos = np.zeros(df.shape[0])\n",
    "    FixYPos = np.zeros(df.shape[0])\n",
    "    FixStartEnd = np.empty(df.shape[0], dtype='U10')\n",
    "    FixStartEnd.fill('') # explicitly fill the array (good practice)\n",
    "    FixDur = np.zeros(df.shape[0])\n",
    "\n",
    "    DistFromPrevFix = np.zeros(df.shape[0])\n",
    "    PrevFixXPos = np.zeros(df.shape[0])\n",
    "    PrevFixYPos = np.zeros(df.shape[0])\n",
    "    prev_fix_x = False # keep track of xy when fixation ends\n",
    "    prev_fix_y = False\n",
    "\n",
    "    PrevFixSampTime = np.zeros(df.shape[0])\n",
    "    prev_fix_sampTime = 0\n",
    "\n",
    "    # iterate thru the original dataframe, thru each sample\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        # make sure not to iterate out of range\n",
    "        if idx < fixDF.shape[0]:\n",
    "\n",
    "            # go to next fixation when fixation ends\n",
    "            if row['sampTime'] > np.array(fixDF.FixEnd)[idx]:\n",
    "                    idx += 1\n",
    "\n",
    "            # make sure not to iterate out of range\n",
    "            if idx < fixDF.shape[0]:\n",
    "\n",
    "                # when samples are within fixation, accumulate FixXPos and FixYPos\n",
    "                if row['sampTime'] >= np.array(fixDF.FixStart)[idx] and row['sampTime'] <= np.array(fixDF.FixEnd)[idx]:\n",
    "\n",
    "                    FixXPos[index] = (np.array(fixDF.XPos)[idx])\n",
    "                    FixYPos[index] = (np.array(fixDF.YPos)[idx])\n",
    "\n",
    "                # label samples on which fixation starts and ends\n",
    "                if row['sampTime'] == np.array(fixDF.FixStart)[idx]:             \n",
    "                    FixStartEnd[index] = 'fix_start'\n",
    "\n",
    "                    if prev_fix_x != False:\n",
    "\n",
    "                        PrevFixXPos[index] = prev_fix_x\n",
    "                        PrevFixYPos[index] = prev_fix_y\n",
    "\n",
    "                        DistFromPrevFix[index] = np.sqrt((np.array(fixDF.XPos)[idx] - prev_fix_x)**2 \n",
    "                                                + (np.array(fixDF.YPos)[idx] - prev_fix_y)**2)\n",
    "                        PrevFixSampTime[index] = prev_fix_sampTime\n",
    "\n",
    "\n",
    "                elif row['sampTime'] == np.array(fixDF.FixEnd)[idx]:                \n",
    "                    FixStartEnd[index] = 'fix_end' \n",
    "                    FixDur[index] = np.array(fixDF.FixDur)[idx]\n",
    "\n",
    "                    prev_fix_x = np.array(fixDF.XPos)[idx]\n",
    "                    prev_fix_y = np.array(fixDF.YPos)[idx]\n",
    "                    prev_fix_sampTime = np.array(row['sampTime'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # add fixations to original dataframe\n",
    "    df['FixXPos'] = np.array(FixXPos)\n",
    "    df['FixYPos'] = np.array(FixYPos)\n",
    "    df['FixStartEnd'] = FixStartEnd\n",
    "    df['FixDur'] = np.array(FixDur)\n",
    "    df['DistFromPrevFix'] = DistFromPrevFix\n",
    "    df['PrevFixSampTime'] = PrevFixSampTime\n",
    "    df['PrevFixXPos'] = PrevFixXPos\n",
    "    df['PrevFixYPos'] = PrevFixYPos\n",
    "    \n",
    "    \n",
    "    # Remove all negative xs, ys\n",
    "    df = df[(df['FixXPos'] > 0) & (df['FixYPos'] > 0) & (df['user_pred_px_x'] > 0) & (df['user_pred_px_y'] > 0)]\n",
    "\n",
    "\n",
    "    # Save the pre-processed dataframe\n",
    "    df.to_csv((os.path.splitext(path)[0] + '_extra.csv'), index=False)  \n",
    "\n",
    "\n",
    "    # Extract only samples when the target was presented\n",
    "    df = df[df.event=='target_on']\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "# # # Label trials with too few data points\n",
    "# # a = df.groupby('trialNr').count().reset_index()\n",
    "# # a = a[['trialNr', 'sampTime']]\n",
    "# # # 3) rename the columns so they would be added\n",
    "# # a.columns = ['trialNr', 'samplesPerTrial']\n",
    "# # df = pd.merge(df, a, on=\"trialNr\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf29185",
   "metadata": {},
   "source": [
    "### For each subject fixations are extracted and added to the original datafile and saved as '[original_filename]_record' + '_extra.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fec41116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant 2024_06_12_10_08_09...\n",
      "\n",
      "\n",
      "\n",
      "Importing and processing: \"C:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_Spaak/data/approved/data\\2024_06_12_10_08_09\\2024_06_12_10_08_09_record.csv\"\n",
      "\tSearching for valid interpolation windows\n",
      "\tReplace interpolation windows with Steffen interpolation\n",
      "\t2-Means clustering started for averaged signal\n",
      "\tDetermining fixations based on clustering weight mean for averaged signal and separate eyes + 2*std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\artem\\anaconda3\\envs\\default\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\artem\\anaconda3\\envs\\default\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\artem\\anaconda3\\envs\\default\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I2MC took 4.922480583190918s to finish!\n"
     ]
    }
   ],
   "source": [
    "# Path to data folders\n",
    "# path_to_data = 'D:/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_Spaak/data'\n",
    "path_to_data = 'C:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_Spaak/data/approved/data'\n",
    "\n",
    "# get all folder names\n",
    "folder_names = os.listdir(path_to_data)\n",
    "\n",
    "# read and process original datafile for each participant\n",
    "for fn in folder_names:\n",
    "    path_to_file = os.path.join(path_to_data, fn, fn+'_record.csv')\n",
    "    \n",
    "    print(f'Processing participant {fn}...')\n",
    "\n",
    "    # Read the file and skip the bad rows    \n",
    "    try:\n",
    "       df = pd.read_csv(path_to_file, on_bad_lines='skip')       \n",
    "    except:\n",
    "        print('File does not exist: ' + path_to_file)\n",
    "        continue\n",
    "        \n",
    "    df1 = extract_fixations(df, path_to_file)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756ede2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
