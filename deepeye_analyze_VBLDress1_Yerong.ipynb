{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571f48c4",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87541a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Enable interactive Matplotlib plots in the notebook\n",
    "%matplotlib qt5\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import astropy.convolution as krn\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c512ec2d",
   "metadata": {},
   "source": [
    "# 2D plot of fixations and raw samples\n",
    "\n",
    "## 1. plot all raw x,y\n",
    "## 2. plot all fixations x,y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98b02c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2d(df, subj_nr, path, bboxes=False, box_w=False, box_h=False, stimuli=False):\n",
    "    \n",
    "    import matplotlib.patches as patches\n",
    "    import ast\n",
    "    import matplotlib.image as mpimg\n",
    "\n",
    "    conditions = ['bags', 'hats', 'sunglasses', 'shoes', 'dresses']\n",
    "\n",
    "\n",
    "    for cond in conditions:\n",
    "\n",
    "        plt.figure()\n",
    "        plt.style.use('ggplot')\n",
    "        plt.title(f'{cond}, #{subj_nr}')\n",
    "\n",
    "        # select condition\n",
    "        a = df[df.stimuli==cond] \n",
    "        \n",
    "        if a.empty:\n",
    "            # Raise an error or handle the case when the DataFrame is empty\n",
    "            raise ValueError(f'There is no data for condition: {cond} in file: {subj_nr}')\n",
    "\n",
    "        raw_h = plt.scatter(a.user_pred_px_x, a.user_pred_px_y, c='orange', alpha=0.5, edgecolors='black')\n",
    "\n",
    "        # remove no fixations/saccades (zeros)\n",
    "        \n",
    "        fix_h = plt.scatter(a.FixXPos[a.FixXPos>0], a.FixYPos[a.FixYPos>0], c='blue', alpha=0.5, edgecolors='black') \n",
    "\n",
    "        # plot center fixation dot\n",
    "        plt.scatter(a.resX.iloc[0]/2, a.resY.iloc[0]/2, c='red')      \n",
    "              \n",
    "        \n",
    "        if bboxes:\n",
    "            # plot image boxes\n",
    "            if cond == 'dresses':\n",
    "                height = 375\n",
    "            else:\n",
    "                width = 250\n",
    "                height = 250\n",
    "            \n",
    "            # get coordinates for the first entry\n",
    "            left_top_coords = a.imageLocations.iloc[0]\n",
    "            \n",
    "            # get paths to image names for that frame\n",
    "            imageNames = a.imageNames.iloc[0]\n",
    "            \n",
    "            # Convert string to actual list\n",
    "            left_top_coords = ast.literal_eval(left_top_coords)\n",
    "#             print(f'coordinates: {left_top_coords}')\n",
    "#             print(f'imageNames: {imageNames}')\n",
    "            imageNames_paths = ast.literal_eval(imageNames)           \n",
    "                        \n",
    "            for stim_idx, coord in enumerate(left_top_coords):                \n",
    "                left = float(coord[0])\n",
    "                top = float(coord[1])            \n",
    "               \n",
    "                rect = patches.Rectangle((left,top),width,height, \n",
    "                                    fill = False,\n",
    "                                    color = \"purple\",\n",
    "                                    linewidth = 2)\n",
    "                \n",
    "                plt.gca().add_patch(rect)\n",
    "                \n",
    "                if stimuli:\n",
    "#                     print('Plotting stimuli images') # draw stimuli images\n",
    "                    \n",
    "                    # Remove the last directory from the path\n",
    "                    new_path = os.path.dirname(path)\n",
    "                    \n",
    "                    # Fix image name if ends on 'png'\n",
    "                    if imageNames_paths[stim_idx][-3:] == 'png':\n",
    "                        imageNames_paths[stim_idx] = imageNames_paths[stim_idx].strip('png') + 'jpg'\n",
    "                    \n",
    "                    # Join the main path with path to stimuli\n",
    "                    new_path = new_path + imageNames_paths[stim_idx][1:]\n",
    "                    \n",
    "                    # Load the images\n",
    "                    image = mpimg.imread(new_path)\n",
    "\n",
    "                    # Define the extent (left, right, bottom, top) in data coordinates\n",
    "                    extent = [left, left+width, top+height, top]\n",
    "                    \n",
    "                    # Plot the image at specific coordinates\n",
    "                    plt.imshow(image, extent=extent)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "        plt.xlim((0, df.resX.iloc[0]))\n",
    "        plt.ylim((df.resY.iloc[0]), 0)\n",
    "\n",
    "        plt.xlabel('Horizontal eye position (pixels)')\n",
    "        plt.ylabel('Vertical eye position (pixels)')\n",
    "\n",
    "        plt.legend((raw_h, fix_h), ('raw samples', 'fixations'), scatterpoints=1)\n",
    "\n",
    "        # save figure\n",
    "        plt.savefig(os.path.join(path, subj_nr+f'_2D{cond}.jpg'), dpi=1000, pad_inches=0)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191879c",
   "metadata": {},
   "source": [
    "# Get latency of all fixations and their order in a trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6226aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fixation latency\n",
    "\n",
    "def getFixationLatency(df):    \n",
    "\n",
    "    # Get timestamp of when target was presented and add it to the dataframe\n",
    "\n",
    "    # 1) get the first time sample when the target is presented\n",
    "    sampTime_df = df.drop_duplicates(subset=['trialNr'],  keep='first', ignore_index=True)\n",
    "\n",
    "    # 2)extract the columns needed\n",
    "    sampTime_df = sampTime_df[['trialNr', 'sampTime']]\n",
    "\n",
    "    # 3) rename the columns so they would be added\n",
    "    sampTime_df.columns = ['trialNr', 'targSampTime']\n",
    "\n",
    "    # 4) merge the target time into the main df (one time per trial)\n",
    "    df = pd.merge(df, sampTime_df, on=\"trialNr\")\n",
    "\n",
    "    # Extract saccade latencies\n",
    "\n",
    "    # 1) select only rows where fixation started\n",
    "    fl_df = df[df.FixStartEnd == 'fix_start']\n",
    "\n",
    "    # 2) select only rows with large enough preceeding saccade\n",
    "#     fl_df = fl_df[fl_df.DistFromPrevFix > 300]\n",
    "\n",
    "    # 3) compute first fixation duration (saccade latency)\n",
    "    fl_df['FixLatency'] = fl_df.sampTime - fl_df.targSampTime\n",
    "\n",
    "    # 4) remove rows where negative Saccade Latencies for trials where no fixation end is present\n",
    "#     fl_df = fl_df[fl_df.FixLatency > 0]\n",
    "\n",
    "    # Clip the negative values to zero. This ensures that fixations that carry over and do not have fix_start have a zero latency\n",
    "    fl_df['FixLatency'] = fl_df['FixLatency'].clip(lower=0)\n",
    "\n",
    "    \n",
    "    # 5)\n",
    "    # Initialize an empty list to hold the groups\n",
    "    fixorder_groups = []\n",
    "    \n",
    "    for name, group in fl_df.groupby('trialNr'):\n",
    "        \n",
    "        # Add a new column with the order (rank) of the values\n",
    "        # 'method='first'' ensures that the order respects the original order in case of ties\n",
    "        group['FixationOrder'] = group['FixLatency'].rank()\n",
    "        \n",
    "        # Append the modified group to the list\n",
    "        fixorder_groups.append(group)\n",
    "        \n",
    "#         print(f'Group: {name}')\n",
    "#         print(group)\n",
    "#         print()        \n",
    "    \n",
    "    # Concatenate all the modified groups back into a single DataFrame\n",
    "    fl_df_modified = pd.concat(fixorder_groups)\n",
    "    \n",
    "    # Extract the columns needed\n",
    "    fl_df_modified = fl_df_modified[['sampTime', 'FixLatency', 'FixationOrder']]\n",
    "    \n",
    "    # Filter out all rows except fix_start and fix_end\n",
    "    df_start_end = df[df['FixStartEnd'].isin(['fix_start', 'fix_end'])]\n",
    "\n",
    "    # Merge the variable into main df\n",
    "    df_modified = pd.merge(df_start_end, fl_df_modified, on=[\"sampTime\"], how=\"left\")\n",
    "    \n",
    "    return df_modified  \n",
    "    \n",
    "# df_modified = getFixationLatency(df1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be4e9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_carryover_fixations_and_merge(df):\n",
    "\n",
    "    trial_duration = 10000 # maximum trial duration\n",
    "    fixcarryover_groups = []\n",
    "    \n",
    "    #***STEP 1: Identify, label and correct carryover fixations ***\n",
    "    # Loop thru trials and identify fixations that carry over the trials\n",
    "    # There are two options:\n",
    "    # 1) Fixation starts during previous trial or event and ends at the beginning of the trial (fix_end event without fix_start event)\n",
    "    # 2) Fixation starts at the end of current trial and finishes after the trial is done (fix_start event without fix_end event)\n",
    "    # If not corrected, this results in incorrect fixation durations, fixation latency, missing fixations \n",
    "    for name, group in df.groupby('trialNr'):\n",
    "        fix_start = group[group.FixStartEnd == 'fix_start'].FixStartEnd\n",
    "        fix_end = group[group.FixStartEnd == 'fix_end'].FixStartEnd\n",
    "\n",
    "        print(fix_start.count(), fix_end.count())\n",
    "\n",
    "        # if trial starts with fixation end, we need to add a fixation start event\n",
    "        if group.FixStartEnd.iloc[0] == 'fix_end':\n",
    "            print(f'Trial {name} starts with fix_end')\n",
    "\n",
    "            # Add extra fixation start event\n",
    "\n",
    "            # Reset variable in the first row\n",
    "            group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
    "            group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n",
    "\n",
    "            # Insert a fix_start event\n",
    "            # Make a copy of the first row with a new index\n",
    "            first_row = group.iloc[0:1].copy()\n",
    "            first_row.index = [-1]  # Assign a negative index\n",
    "            first_row.FixStartEnd = 'fix_start_carryover_inserted_start'\n",
    "            first_row.FixDur = 0\n",
    "            first_row.FixLatency = 0\n",
    "\n",
    "\n",
    "            # Prepend the copied first row to the original DataFrame\n",
    "            group = pd.concat([first_row, group])\n",
    "\n",
    "            # Reset the index if you want a continuous numeric index\n",
    "            group = group.sort_index().reset_index(drop=True)\n",
    "\n",
    "            # Now we need to re-rank the order of fixations in the trial, since we added a new one in the beginning\n",
    "            group['FixationOrder'] = group['FixLatency'].rank()\n",
    "\n",
    "\n",
    "        # if trial ends with fixation start, we need to add a fixation end event\n",
    "        if group.FixStartEnd.iloc[-1] == 'fix_start':\n",
    "            print(f'Trial {name} ends with fix_start')\n",
    "\n",
    "            # Add fixation end event\n",
    "            # Reset variable in the last row\n",
    "            group.FixStartEnd.iloc[-1] = 'fix_start_carryover_inserted_end'\n",
    "            group.FixDur.iloc[-1] = 0\n",
    "\n",
    "            # Insert a fix_start event\n",
    "            # Make a copy of the last row with a ne index\n",
    "            last_row = group.iloc[[-1]].copy()        \n",
    "            last_row.index = last_row.index+1 # Assign the next index\n",
    "            last_row.FixStartEnd = 'fix_end_carryover_inserted_end'\n",
    "            last_row.FixDur = (last_row.targSampTime + trial_duration) - last_row.sampTime\n",
    "            last_row.FixLatency = 0\n",
    "            last_row.FixationOrder= 0\n",
    "\n",
    "            # Append the copied first row to the original DataFrame\n",
    "            group = pd.concat([group, last_row])\n",
    "\n",
    "            # Reset the index if you want a continuous numeric index\n",
    "            group = group.sort_index().reset_index(drop=True)                      \n",
    "\n",
    "\n",
    "\n",
    "        # Accumulate groups into a list\n",
    "        fixcarryover_groups.append(group)\n",
    "\n",
    "    # Concatenate all the modified groups back into a single DataFrame\n",
    "    fc_df = pd.concat(fixcarryover_groups)\n",
    "\n",
    "    #*** STEP 2: Collapse all fixation events, such that all information is provided per each fixation****\n",
    "    \n",
    "    # *** 1. Merge all fixation events for fixations that happen within trial ***\n",
    "    \n",
    "    # Get only fix_start events\n",
    "    df_fix_start = fc_df[fc_df.FixStartEnd == 'fix_start']\n",
    "    # Drop the FixDur column, which should be empty for fix_start events\n",
    "    df_fix_start = df_fix_start.drop('FixDur', axis=1)\n",
    "\n",
    "    # Get only fix_end events\n",
    "    df_fix_end = fc_df[fc_df.FixStartEnd == 'fix_end']\n",
    "    # Select only the relevant events from fix_end events\n",
    "    df_fix_end = df_fix_end[[\"FixXPos\", \"FixYPos\", \"FixDur\"]]\n",
    "\n",
    "\n",
    "    # Merge fix start and end for the same fixations\n",
    "    df_merged = pd.merge(df_fix_start, df_fix_end, on=[\"FixXPos\", \"FixYPos\"])\n",
    "\n",
    "    #*** 2. Merge carryover fixation which missed the fix_start event ***\n",
    "    \n",
    "    # Get only fix_start_carryover_inserted_start events\n",
    "    df_fix_start_insert_start = fc_df[fc_df.FixStartEnd == 'fix_start_carryover_inserted_start']\n",
    "    df_fix_start_insert_start = df_fix_start_insert_start.drop('FixDur', axis=1)\n",
    "\n",
    "    # Get only fix_end_carryover_inserted_start events\n",
    "    df_fix_end_insert_start = fc_df[fc_df.FixStartEnd == 'fix_end_carryover_inserted_start']\n",
    "    # Select only the relevant events from fix_end events\n",
    "    df_fix_end_insert_start = df_fix_end_insert_start[[\"FixXPos\", \"FixYPos\", \"FixDur\"]]\n",
    "\n",
    "    df_merged_insert_start = pd.merge(df_fix_start_insert_start, df_fix_end_insert_start, on=[\"FixXPos\", \"FixYPos\"])\n",
    "\n",
    "    #*** 3. Merge carryover fixations which missed the fix_end event ***\n",
    "    \n",
    "    # Get only fix_start_carryover_inserted_end events\n",
    "    df_fix_start_insert_end = fc_df[fc_df.FixStartEnd == 'fix_start_carryover_inserted_end']\n",
    "    df_fix_start_insert_end = df_fix_start_insert_end.drop('FixDur', axis=1)\n",
    "\n",
    "    # Get only fix_end_carryover_inserted_end events\n",
    "    df_fix_end_insert_end = fc_df[fc_df.FixStartEnd == 'fix_end_carryover_inserted_end']\n",
    "    # Select only the relevant events from fix_end events\n",
    "    df_fix_end_insert_end = df_fix_end_insert_end[[\"FixXPos\", \"FixYPos\", \"FixDur\"]]\n",
    "\n",
    "    df_merged_insert_end = pd.merge(df_fix_start_insert_end, df_fix_end_insert_end, on=[\"FixXPos\", \"FixYPos\"])\n",
    "\n",
    "    #*** 4. Concatenate all carryover fixations***\n",
    "    # Now concatenate all carryover fixations, inserted_start and inserted_end\n",
    "    df_carryover = pd.concat([df_merged_insert_start, df_merged_insert_end], ignore_index=True)\n",
    "\n",
    "    # Sort the combined DataFrame based on frameNr\n",
    "    df_carryover = df_carryover.sort_values(by='frameNr')\n",
    "\n",
    "    \n",
    "    # *** 5. Now concatenate carryover fixations with within_trial fixations ***\n",
    "    df_final = pd.concat([df_merged, df_carryover], ignore_index=True)\n",
    "    # Sort based on frameNr\n",
    "    df_final = df_final.sort_values(by='frameNr')\n",
    "\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# df_final = handle_carryover_fixations_and_merge(df_modified)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a771d6",
   "metadata": {},
   "source": [
    "# Calculating AOI for each fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0573be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAOI(df):  \n",
    "    \n",
    "    \"\"\"\n",
    "    df should contain only fixation events, no raw data\n",
    "    \"\"\"\n",
    "    \n",
    "    def is_point_in_box(point, box):\n",
    "        \"\"\"\n",
    "        Determine if a point is within a bounding box.\n",
    "\n",
    "        Parameters:\n",
    "        - point: A tuple (x, y) representing the point.\n",
    "        - box: A tuple ((x1, y1), (x2, y2)) representing the bounding box, \n",
    "               where (x1, y1) is the top-left corner and (x2, y2) is the bottom-right corner.\n",
    "\n",
    "        Returns:\n",
    "        - True if the point is within the box, False otherwise.\n",
    "        \"\"\"\n",
    "        px, py = point\n",
    "        (x1, y1), (x2, y2) = box\n",
    "\n",
    "        return x1 <= px <= x2 and y1 <= py <= y2\n",
    "\n",
    "    def get_bounding_box_assignment(boxes, point):\n",
    "        \"\"\"\n",
    "        Determine the bounding box a point belongs to.\n",
    "\n",
    "        Parameters:\n",
    "        - boxes: A list of tuples representing the bounding boxes.\n",
    "                 Each bounding box is defined as ((x1, y1), (x2, y2)).\n",
    "        - point: A tuple (x, y) representing the point.\n",
    "\n",
    "        Returns:\n",
    "        - The index of the bounding box the point belongs to, or None if it doesn't belong to any boxes.\n",
    "        \"\"\"\n",
    "        for i, box in enumerate(boxes):\n",
    "            if is_point_in_box(point, box):\n",
    "                return i\n",
    "        \n",
    "        return 'None'\n",
    "\n",
    "\n",
    "    import ast\n",
    "    width = 250\n",
    "    height = 250\n",
    "    imageName = 'None'\n",
    "    bbox_assignments = []\n",
    "    stim_assignments = []\n",
    "\n",
    "    aoi_df = df\n",
    "\n",
    "    for index, row in aoi_df.iterrows():\n",
    "        \n",
    "        if row.stimuli == 'dresses':\n",
    "            height = 375            \n",
    "        \n",
    "        # Get all stimuli names for this trial\n",
    "        imageNames = row.imageNames\n",
    "        \n",
    "        # Convert str to actual list\n",
    "        imageNames = ast.literal_eval(imageNames)\n",
    "\n",
    "        # Bounding boxes for this trial\n",
    "        bounding_boxes = []\n",
    "\n",
    "        # Get coordinates of stimuli for this fixation\n",
    "        left_top_coords = row.imageLocations\n",
    "\n",
    "        # Convert string to actual list\n",
    "        left_top_coords = ast.literal_eval(left_top_coords)\n",
    "\n",
    "        # Iterate over bboxes\n",
    "        for coord in left_top_coords:      \n",
    "            # Assemble coordinates for the bounding boxes\n",
    "            x1 = coord[0]\n",
    "            y1 = coord[1]\n",
    "            x2 = coord[0] + width\n",
    "            y2 = coord[1] + height\n",
    "            bounding_boxes.append([(x1,y1), (x2,y2)])        \n",
    "\n",
    "        # Get fixation coordinates\n",
    "        point = (row.FixXPos, row.FixYPos)\n",
    "        # get the index of the AOI where this fixation point falls\n",
    "        assignment = get_bounding_box_assignment(bounding_boxes, point)\n",
    "\n",
    "        # if fixation in the bounding box, get the stimulus name for this bounding box\n",
    "        if assignment != 'None':\n",
    "            imageName = imageNames[assignment].split('/')[-1]\n",
    "        else:\n",
    "            # To specify None, add the stimuli event \n",
    "            imageName = 'None_' + row.stimuli\n",
    "            assignment = assignment + '_' + row.stimuli\n",
    "\n",
    "\n",
    "#         print(f'The point {point} belongs to bounding box: {assignment}, image:{imageName}')\n",
    "\n",
    "\n",
    "        # Accumulate assignements\n",
    "        bbox_assignments.append(assignment)\n",
    "        stim_assignments.append(imageName)\n",
    "\n",
    "    aoi_df['AOI_bbox'] = bbox_assignments\n",
    "    aoi_df['AOI_stim'] = stim_assignments\n",
    "    \n",
    "    # Reset index\n",
    "    aoi_df = aoi_df.reset_index(drop=True)\n",
    "       \n",
    "    \n",
    "    return aoi_df\n",
    "\n",
    "# a = addAOI(df_final)\n",
    "# a.to_csv(path +'/sample_participant_VBLExp1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6413ce51",
   "metadata": {},
   "source": [
    "# Analyze all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f90e7e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'D:/Dropbox/DeepEye_Pilots/VBL_Exp1/data/approved\\analysis_tmp' was created.\n",
      "Processing participant 2024_02_19_08_03_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\1438454985.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fl_df['FixLatency'] = fl_df.sampTime - fl_df.targSampTime\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\1438454985.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fl_df['FixLatency'] = fl_df['FixLatency'].clip(lower=0)\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 19\n",
      "Trial 0 starts with fix_end\n",
      "15 15\n",
      "12 13\n",
      "Trial 2 starts with fix_end\n",
      "14 15\n",
      "Trial 3 starts with fix_end\n",
      "16 17\n",
      "Trial 4 starts with fix_end\n",
      "Processing participant 2024_02_19_08_03_44...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\1438454985.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fl_df['FixLatency'] = fl_df.sampTime - fl_df.targSampTime\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\1438454985.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fl_df['FixLatency'] = fl_df['FixLatency'].clip(lower=0)\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[-1] = 'fix_start_carryover_inserted_end'\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[-1] = 0\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 17\n",
      "Trial 0 starts with fix_end\n",
      "15 15\n",
      "Trial 1 starts with fix_end\n",
      "Trial 1 ends with fix_start\n",
      "19 19\n",
      "13 14\n",
      "Trial 3 starts with fix_end\n",
      "18 18\n",
      "Processing participant 2024_02_19_08_04_13...\n",
      "21 22\n",
      "Trial 0 starts with fix_end\n",
      "20 21\n",
      "Trial 1 starts with fix_end\n",
      "16 17\n",
      "Trial 2 starts with fix_end\n",
      "15 16\n",
      "Trial 3 starts with fix_end\n",
      "15 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\1438454985.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fl_df['FixLatency'] = fl_df.sampTime - fl_df.targSampTime\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\1438454985.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fl_df['FixLatency'] = fl_df['FixLatency'].clip(lower=0)\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixStartEnd.iloc[0] = 'fix_end_carryover_inserted_start' # label such fixation event\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_1052\\2621730654.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group.FixDur.iloc[0] = group.sampTime.iloc[0] - group.targSampTime.iloc[0] # recalculate fixation duration\n"
     ]
    }
   ],
   "source": [
    "# Path to data folders\n",
    "\n",
    "# path = 'C:/Users/artem/Dropbox/DeepEye_Pilots/VBL_Exp1/data/approved'\n",
    "path = 'D:/Dropbox/DeepEye_Pilots/VBL_Exp1/data/approved'\n",
    "\n",
    "def create_directory_if_not_exists(directory_path):\n",
    "    try:\n",
    "        os.makedirs(directory_path)\n",
    "        print(f\"Directory '{directory_path}' was created.\")\n",
    "    except FileExistsError:\n",
    "        # The directory already exists, no need to create it.\n",
    "        print(f\"Directory '{directory_path}' already exists.\")\n",
    "\n",
    "# definde data ana analysis directories and create them if they don't exist yet\n",
    "path_to_data = os.path.join(path, 'data')\n",
    "path_to_analysis = os.path.join(path, 'analysis')\n",
    "create_directory_if_not_exists(path_to_analysis)\n",
    "\n",
    "output_dfs = []\n",
    "# get all folder names\n",
    "folder_names = os.listdir(path_to_data)\n",
    "\n",
    "# read and process datafile with fixations (_extra) for each participant\n",
    "for fn in folder_names:\n",
    "    path_to_file = os.path.join(path_to_data, fn, fn+'_record_extra.csv')\n",
    "    \n",
    "    print(f'Processing participant {fn}...')\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(path_to_file)        \n",
    "    except:\n",
    "        print('File does not exist: ' + path_to_file)\n",
    "        continue\n",
    "        \n",
    "    # Extract only samples when the target was presented\n",
    "    df1 = df[df.event=='target_on']\n",
    "    \n",
    "    try:\n",
    "        plot2d(df1, fn, path_to_analysis, bboxes=True, stimuli=True)\n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "    df1 = getFixationLatency(df1)\n",
    "    df1 = handle_carryover_fixations_and_merge(df1)\n",
    "    df1 = addAOI(df1)\n",
    "    \n",
    "    # Accumulate analyzed data across participants\n",
    "    output_dfs.append(df1)\n",
    "    \n",
    "output_df = pd.concat(output_dfs)\n",
    "output_df.to_csv(os.path.join(path_to_analysis, 'allSubjects_VBLExp1.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255d438",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "293a2ad5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_PreferentialViewing/Pilot_PreferentialViewing/Young/Approved\\\\analysis\\\\allSubjects_NoveltyIndex.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_PreferentialViewing/Pilot_PreferentialViewing/Young/Approved\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m path_to_analysis \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalysis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m output_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_analysis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallSubjects_NoveltyIndex.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# filter out excluded participants\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# '2024_01_15_14_19_20' was the second time, '2024_01_26_17_16_28' too few frames\u001b[39;00m\n\u001b[0;32m      8\u001b[0m output_df \u001b[38;5;241m=\u001b[39m output_df[\u001b[38;5;241m~\u001b[39moutput_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeepeye-id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024_01_15_14_19_20\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024_01_26_17_16_28\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n",
      "File \u001b[1;32mc:\\Users\\Artem\\Anaconda3\\envs\\default\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Artem\\Anaconda3\\envs\\default\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Artem\\Anaconda3\\envs\\default\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Artem\\Anaconda3\\envs\\default\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Artem\\Anaconda3\\envs\\default\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Artem\\Anaconda3\\envs\\default\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Artem\\Anaconda3\\envs\\default\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_PreferentialViewing/Pilot_PreferentialViewing/Young/Approved\\\\analysis\\\\allSubjects_NoveltyIndex.csv'"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/artem/Dropbox/Appliedwork/CognitiveSolutions/Projects/DeepEye/TechnicalReports/TechnicalReport1/Test_PreferentialViewing/Pilot_PreferentialViewing/Young/Approved'\n",
    "path_to_analysis = os.path.join(path, 'analysis')\n",
    "\n",
    "output_df = pd.read_csv(os.path.join(path_to_analysis, 'allSubjects_NoveltyIndex.csv'))\n",
    "\n",
    "# filter out excluded participants\n",
    "# '2024_01_15_14_19_20' was the second time, '2024_01_26_17_16_28' too few frames\n",
    "output_df = output_df[~output_df['deepeye-id'].isin(['2024_01_15_14_19_20', '2024_01_26_17_16_28'])]\n",
    "\n",
    "# group data\n",
    "total_count = output_df.groupby(['pp_id', 'deepeye-id']).noveltyIdx_fixCountProp.count()\n",
    "fixCountProp = output_df.groupby(['pp_id', 'deepeye-id']).noveltyIdx_fixCountProp.mean()\n",
    "fixDurProp = output_df.groupby(['pp_id', 'deepeye-id']).noveltyIdx_fixDurProp.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa131be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
